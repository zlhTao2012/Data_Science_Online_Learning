{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Machine Learning Classification (Certificate) - Week 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# The Logistics Regression on ***Machine Learning (Andrew Ng) - Classfication***  is very similar to Method 1, but the calculation is under the minimization of negative log likelihood "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Maximize the Log Likelihood "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood\n",
    "$$\n",
    "\\sum_{i=0}^N{P(y_i | x_i,w)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probablity model predicts y = +1:\n",
    "$$\n",
    "P(y = +1 | x,w) = \\frac{1}{1+exp{(-w \\: h(x))}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probablity model predicts y = -1:\n",
    "$$\n",
    "P(y = -1 | x,w) = 1- P(y = +1 | x,w) = 1 - \\frac{1}{1+exp{(-w \\: h(x))}} = \\frac{exp{(-w \\: h(x))}}{1+exp{(-w \\: h(x))}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Log Likelihood\n",
    "$$\n",
    "ll(w) = \\sum_{i=0}^N{lnP(y_i | x_i,w)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "ll(w) = \\sum_{i=0}^N{(\\Pi(1[y_i = +1])^*lnP(y = +1 | x_i,w) + \\Pi(1[y_i = -1])^{**}lnP(y = -1 | x_i,w))} \n",
    "$$\n",
    "\n",
    "\n",
    "$$\\mathbf{where} \\:\\: ^* \\mathbf{Function \\: \\Pi(1[y_i = +1])} \\: means \\: if \\: y_i \\: = \\: +1 \\:then \\: output \\: is \\: 1 \\: else \\: output \\: is \\: 0 \\: ; \\: $$\n",
    "$$ and ^{**} \\: \\mathbf{Function \\: \\Pi(1[y_i = -1])} \\: means \\: if \\: y_i \\: = \\: -1 \\:then \\: output \\: is \\: 1 \\: else \\: output \\: is \\: 0 \\:$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "ll(w) = \\sum_{i=0}^N{(\\Pi(1[y_i = +1])ln(\\frac{1}{1+exp{(-w^T \\: h(x))}}) + (1-\\Pi(1[y_i = +1]))ln(\\frac{exp{(-w^T \\: h(x))}}{1+exp{(-w^T \\: h(x))}}))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "ll(w) = \\sum_{i=0}^N{(-\\Pi(1[y_i = +1])ln({1+exp{(-w^T \\: h(x))}}) + (1-\\Pi(1[y_i = +1]))(  -w^T \\: h(x) - ln{(1+exp{(-w^T \\: h(x))}})))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "ll(w) = \\sum_{i=0}^N{(-\\Pi(1[y_i = +1])ln({1+exp{(-w^T \\: h(x))}}) - (1-\\Pi(1[y_i = +1]))ln{(1+exp{(-w^T \\: h(x))}}))  + (1-\\Pi(1[y_i = +1]))(  -w^T \\: h(x)))}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{Maximize} \\qquad \\mathbf{E_{(Likelihood)}} = \\sum_{i=0}^N{(-ln{(1+exp{(-w^T \\: h(x))}}))  + (1-\\Pi(1[y_i = +1]))(  -w^T \\: h(x)))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# II Derivative of the Log Likelihood Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\n",
    "\\frac{\\Delta \\mathbf{E_{(Likelihood)}}} {\\Delta w} \n",
    "= \\sum_{i=0}^N{(\\frac{\\Delta(-ln{(1+exp{(-w^T \\: h(x))}}))  + (1-\\Pi(1[y_i = +1]))(  -w^T \\: h(x))) } {\\Delta w} )}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\n",
    "\\frac{\\Delta \\mathbf{E_{(Likelihood)}}} {\\Delta w} = \\sum_{i=0}^N{(h(x) \\frac{exp{(-w^T \\: h(x))}}{1+exp{(-w^T \\: h(x))}} - (1-\\Pi(1[y_i = +1])) h(x))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\n",
    "\\frac{\\Delta \\mathbf{E_{(Likelihood)}}} {\\Delta w} = \\sum_{i=0}^N{(h(x) P(y = -1 | x,w) - (1-\\Pi(1[y_i = +1])) h(x))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\Delta \\mathbf{E_{(Likelihood)}}} {\\Delta w} = \\sum_{i=0}^N{(h(x) (1- P(y = +1 | x,w)) - (1-\\Pi(1[y_i = +1])) h(x))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{Finally\\qquad}  \\frac{\\Delta \\mathbf{E_{(Likelihood)}}} {\\Delta w} = \\sum_{i=0}^N{(h(x) (\\Pi(1[y_i = +1])- P(y = +1 | x,w)))} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - Logistics Regression Ascent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize the weights at t = 0 to w(0)\n",
    "### 2. For t = 0, 1, 2,... do\n",
    "### 3. Compute the gradient: \n",
    "$$\n",
    "\\Delta \\mathbf{E_{(Likelihood)}} = \\sum_{i=0}^N{(h(x) (\\Pi(1[y_i = +1])- P(y = +1 | x,w)))}       \n",
    "$$\n",
    "### 4. Update the weights: w(t+1) = w(t) + $\\eta \\Delta \\mathbf{E_{(Likelihood)}}$\n",
    "### 5. Iterate to the next step until it is time to stop\n",
    "### 6. Return the final weights w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Learning from Data (Caltech)  Lecture 9 - The Linear Model II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  I - From Maximized Likelihood to Minimized Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximized the Likelihood\n",
    "\n",
    "Since both the y and the $h(\\mathbf{x})\\mathbf{w}^T$ are both monotonic(increase) in logistics regression, then the logistics regression likelihood can be presented as P(y | x) = $\\theta(y \\: h(\\mathbf{x})\\mathbf{w}^T )$. \n",
    "$$ Likelihood \\: of \\: D = (\\mathbf{x1}, y1), ...,(\\mathbf{x_N}, y_N) \\: is \\:\n",
    "\\sum_{i=0}^N P(\\mathbf{y}_i|\\mathbf{x}_i) = \\sum_{i=0}^N \\theta(\\mathbf{y}_i \\: h(\\mathbf{x}_i)\\mathbf{w}_i^T) $$ \n",
    "\n",
    "\n",
    "$$\\mathbf{where} \\:\\: \\theta(g) = {\\frac{1}{1 + \\exp(-g)}} $$\n",
    "$$\n",
    "Therefore \\: we \\: can \\: \\mathbf{Maximize } \\qquad Likelihood \\: of \\: D = \\sum_{i=0}^N{\\frac{1}{1 + \\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)}}         \n",
    "$$\n",
    "\n",
    "### Convert to Minimized the Negative Likelihood -  The New Cost Function\n",
    "\n",
    "$$\n",
    "\\mathbf{Minimize} \\qquad \\mathbf{E_{(Cost)}} = -\\sum_{i=0}^N{\\frac{1}{1 + \\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)}}         \n",
    "$$\n",
    "$$\n",
    "\\mathbf{Is\\: Equal\\: To \\: Minimize} \\qquad \\mathbf{E_{(Cost)}} = \\sum_{i=0}^N{{1 + \\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)}}         \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Derivative of the Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\Delta \\mathbf{E_{(Cost)}}} {\\Delta w} = -\\sum_{i=0}^N\\frac{\\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)\\mathbf{y}_i\\mathbf{x}_i}{1 + \\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)}        \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta \\mathbf{E_{(Cost)}}} {\\Delta w} = -\\sum_{i=0}^N\\frac{\\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)\\mathbf{y}_i\\mathbf{x}_i (1 + \\exp(\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)}{(1 + \\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T))(1 + \\exp(\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)}       \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta \\mathbf{E_{(Cost)}}} {\\Delta w} = -\\sum_{i=0}^N\\frac{\\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)\\mathbf{y}_i\\mathbf{x}_i  + \\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T+\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)\\mathbf{y}_i\\mathbf{x}_i}{(1 + \\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T))(1 + \\exp(\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)}       \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta \\mathbf{E_{(Cost)}}} {\\Delta w} = -\\sum_{i=0}^N\\frac{\\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)\\mathbf{y}_i\\mathbf{x}_i  + \\mathbf{y}_i\\mathbf{x}_i}{(1 + \\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T))(1 + \\exp(\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)}       \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta \\mathbf{E_{(Cost)}}} {\\Delta w} = -\\sum_{i=0}^N\\frac{(\\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)+1)\\mathbf{y}_i\\mathbf{x}_i}{(1 + \\exp(-\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T))(1 + \\exp(\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T)}       \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{Finally\\qquad}  \\frac{\\Delta \\mathbf{E_{(Cost)}}} {\\Delta w} = -\\sum_{i=0}^N\\frac{\\mathbf{y}_i\\mathbf{x}_i}{(1 + \\exp(\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T))}       \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - Logistics Regression Descent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize the weights at t = 0 to w(0)\n",
    "### 2. For t = 0, 1, 2,... do\n",
    "### 3. Compute the gradient: \n",
    "$$\n",
    "\\Delta \\mathbf{E_{(Cost)}} = -\\sum_{i=0}^N\\frac{\\mathbf{y}_i\\mathbf{x}_i}{(1 + \\exp(\\mathbf{y}_ih(\\mathbf{x}_i)\\mathbf{w}^T))}       \n",
    "$$\n",
    "### 4. Update the weights: w(t+1) = w(t) - $\\eta \\Delta \\mathbf{E_{(Cost)}}$\n",
    "### 5. Iterate to the next step until it is time to stop\n",
    "### 6. Return the final weights w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
